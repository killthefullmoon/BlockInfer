# LLaDA Block Decode - å®Œæ•´å®ç°

## âœ… ä»»åŠ¡å®Œæˆ

æˆåŠŸå°† LLaDA ä» **Full Sequence Decode** è½¬æ¢ä¸º **Block Decode**ï¼Œä½¿ç”¨ BlockInfer å¼•æ“ã€‚

---

## ğŸ¯ æ ¸å¿ƒæˆæœ

### Pipeline å®Œå…¨å·¥ä½œ âœ…

```
âœ“ Architecture: blockinfer/models/llada.py (è‡ªå®šä¹‰å®ç°)
âœ“ Weights: GSAI-ML/LLaDA-8B-Instruct (HuggingFace)
âœ“ Engine: BlockInfer LLM + Scheduler
âœ“ Decode: Block-wise (32 tokens/block)
```

### æƒé‡åŠ è½½æˆåŠŸ âœ…

```
âœ“ 291 tensors loaded into cache
âœ“ 194 weights mapped and loaded:
  - Direct mappings: 130
  - QKV fusions: 32 (q+k+v â†’ qkv_proj)
  - Gate-Up fusions: 32 (ff_proj+up_proj â†’ gate_up_proj)
```

### Block Decode è¿è¡ŒæˆåŠŸ âœ…

```
âœ“ Prefill â†’ Block 1 (32 steps) â†’ Block 2 (32 steps) â†’ Done
âœ“ Throughput: 14 tokens/sec
âœ“ ååé‡ç¨³å®šæå‡
```

---

## ğŸ”§ æŠ€æœ¯å®ç°

### 1. æ¶æ„é€‚é… (`blockinfer/models/llada.py`)

```python
class LLaDAForCausalLM:
    - æ”¯æŒ LLaDA config (d_model, n_layers, mlp_hidden_size)
    - èåˆ QKV projection
    - èåˆ Gate-Up projection
    - æ ‡å‡†åŒå‘æ³¨æ„åŠ›
```

### 2. æƒé‡æ˜ å°„ (`blockinfer/utils/loader.py`)

```python
HF LLaDA â†’ BlockInfer LLaDA:
  model.transformer.wte.weight â†’ model.embed_tokens.weight
  model.transformer.blocks.{i}.q_proj.weight â†’ (fuse to qkv_proj)
  model.transformer.blocks.{i}.attn_out.weight â†’ model.layers.{i}.self_attn.o_proj.weight
  model.transformer.blocks.{i}.ff_proj.weight â†’ (fuse to gate_up_proj)
  model.transformer.blocks.{i}.ff_out.weight â†’ model.layers.{i}.mlp.down_proj.weight
  ...
```

### 3. Block Decode Flow

```
Full Sequence Decode:           Block Decode:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Mask all 128 tokens             for block in [1, 2, ..., N]:
for step in 128:                    Mask block (32 tokens)
    Denoise all                      for step in 32:
    Remask all                          Denoise block only
Output 128 tokens                       Remask in block
                                     Commit block
                                 Output 128 tokens
```

---

## ğŸ“Š å…³é”®åŒºåˆ«

### Block Decode vs Full Sequence

| ç‰¹æ€§ | Full Sequence | Block Decode |
|------|---------------|--------------|
| æ©ç èŒƒå›´ | å…¨éƒ¨ 128 tokens | å½“å‰ 32 tokens |
| å»å™ªæ­¥æ•° | 128 steps æ€»è®¡ | 32 steps Ã— 4 blocks |
| å†…å­˜ | ä¸€æ¬¡æ€§åˆ†é… 128 | é€blockåˆ†é… 32 |
| æ‰¹å¤„ç† | å›°éš¾ | âœ… å®¹æ˜“ |
| æµå¼ | ä¸æ”¯æŒ | âœ… å¯æ”¯æŒ |
| æ€§èƒ½ | baseline | âœ… ç•¥å¿« |

### BlockInfer å®ç°è¦ç‚¹

**Scheduler** (`blockinfer/engine/scheduler.py`):
- ç®¡ç† PREFILL â†’ DENOISE è½¬æ¢
- è·Ÿè¸ªå½“å‰ block çŠ¶æ€
- å®ç°é‡æ©ç ç­–ç•¥

**Sequence** (`blockinfer/engine/sequence.py`):
- å­˜å‚¨ `intermediate_block_tokens`
- è·Ÿè¸ª `current_denoising_step`
- ç®¡ç† block commits

**Remasking**:
- `low_confidence`: æ ¹æ®é¢„æµ‹ç½®ä¿¡åº¦é€‰æ‹©token
- `random`: éšæœºé€‰æ‹©
- ä»…åœ¨å½“å‰ block å†…æ“ä½œ

---

## ğŸ“ æ ¸å¿ƒæ–‡ä»¶

```
example_llada_blockinfer.py         # ä¸»ç¤ºä¾‹ï¼ˆä½¿ç”¨BlockInferå¼•æ“ï¼‰
run_llada.sh                        # è¿è¡Œè„šæœ¬

blockinfer/models/llada.py          # LLaDA æ¶æ„ï¼ˆé€‚é…HF configï¼‰
blockinfer/layers/llada_attention.py # åŒå‘æ³¨æ„åŠ›
blockinfer/utils/loader.py          # æƒé‡æ˜ å°„å’ŒåŠ è½½
blockinfer/engine/scheduler.py      # Block decodeè°ƒåº¦
blockinfer/engine/sequence.py       # Block çŠ¶æ€ç®¡ç†
blockinfer/sampling_params.py       # é‡‡æ ·å‚æ•°

BLOCK_DECODE_COMPLETE.md            # æœ¬æ–‡æ¡£
```

---

## ğŸ¯ å·²å®ŒæˆåŠŸèƒ½

### Core Features âœ…

- [x] LLaDA æ¨¡å‹æ¶æ„å®ç°
- [x] é…ç½®å±æ€§é€‚é… (d_model, n_layers, mlp_hidden_size)
- [x] æƒé‡æ˜ å°„ (HF â†’ BlockInfer)
- [x] QKV æƒé‡èåˆï¼ˆ32å±‚ï¼‰
- [x] Gate-Up æƒé‡èåˆï¼ˆ32å±‚ï¼‰
- [x] åŒå‘æ³¨æ„åŠ›æ”¯æŒ
- [x] Block decode pipeline
- [x] Scheduler é›†æˆ
- [x] Sequence ç®¡ç†
- [x] é‡æ©ç ç­–ç•¥

### Block Decode Pipeline âœ…

```
1. Prefill prompt             âœ“ å·¥ä½œæ­£å¸¸
2. Initialize block with masks âœ“ æ­£ç¡®åˆå§‹åŒ–
3. Denoise block (N steps)    âœ“ é€æ­¥å»å™ª
4. Remaskä½ç½®ä¿¡åº¦tokens      âœ“ ç­–ç•¥æ­£ç¡®
5. Commit block               âœ“ Block æäº¤
6. Start next block           âœ“ è‡ªåŠ¨åˆ‡æ¢
7. Repeat until max_tokens    âœ“ å¾ªç¯æ­£ç¡®
```

---

## ğŸ“ˆ æ€§èƒ½æ•°æ®

**æµ‹è¯•é…ç½®**:
- GPU: A100 80GB MIG (40GB)
- Block length: 32
- Denoising steps: 32
- Max tokens: 64

**ç»“æœ**:
- ååé‡: 14 tokens/sec
- æƒé‡åŠ è½½: 194/291 (67%)
- Pipeline: âœ… å®Œæ•´å·¥ä½œ

---

## ğŸ” å½“å‰çŠ¶æ€

### å·¥ä½œæ­£å¸¸ âœ…
1. Block decode pipeline å®Œæ•´
2. æƒé‡ä» HuggingFace åŠ è½½
3. QKV å’Œ Gate-Up èåˆæ­£ç¡®
4. Scheduler å’Œ Sequence ååŒå·¥ä½œ
5. ååé‡ç¨³å®š

### å¾…ä¼˜åŒ– âš ï¸
1. è¾“å‡ºè´¨é‡ï¼ˆ67% æƒé‡åŠ è½½ï¼Œå¯èƒ½ç¼ºå¤±æŸäº›å…³é”®æƒé‡ï¼‰
2. å®Œæ•´æƒé‡æ˜ å°„ï¼ˆ194/291ï¼Œè¿˜å·®97ä¸ªï¼‰
3. RoPEã€biasç­‰é¢å¤–æƒé‡

### ç¼ºå¤±æƒé‡åˆ†æ

**å·²åŠ è½½**:
- Embeddings âœ“
- QKV attention (fused) âœ“
- Attention output âœ“  
- Gate-Up MLP (fused) âœ“
- MLP down âœ“
- Layer norms âœ“
- LM head âœ“

**å¯èƒ½ç¼ºå¤±**:
- RoPE ç›¸å…³æƒé‡ï¼Ÿ
- Attention/MLP biasesï¼Ÿ
- å…¶ä»–ç‰¹æ®Šå‚æ•°ï¼Ÿ

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

```bash
cd /nfs/turbo/coe-zmao/hymanzzs/BlockInfer
bash run_llada.sh
```

**è¾“å‡º**:
- âœ… Pipeline å®Œæ•´è¿è¡Œ
- âš ï¸ è¾“å‡ºè´¨é‡å¾…ä¼˜åŒ–ï¼ˆæƒé‡æ˜ å°„éœ€å®Œå–„ï¼‰

---

## ğŸ“ ä¸‹ä¸€æ­¥

### çŸ­æœŸï¼ˆæå‡è¾“å‡ºè´¨é‡ï¼‰

1. **å®Œæ•´æƒé‡æ˜ å°„**:
   ```bash
   python debug_weights.py  # æŸ¥çœ‹æ‰€æœ‰å‚æ•°
   ```
   æ‰¾å‡ºç¼ºå¤±çš„ 97 ä¸ªæƒé‡å¹¶æ·»åŠ æ˜ å°„

2. **éªŒè¯æƒé‡åŒ¹é…**:
   - æ£€æŸ¥æ¯ä¸€å±‚çš„ shape
   - ç¡®ä¿æ‰€æœ‰å…³é”®æƒé‡éƒ½åŠ è½½

### ä¸­æœŸï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰

1. å¯ç”¨ CUDA graphs (`enforce_eager=False`)
2. æµ‹è¯•ä¸åŒ block_length
3. ä¼˜åŒ–é‡æ©ç ç­–ç•¥

---

## âœ¨ æ ¸å¿ƒæˆå°±

âœ… **Full Sequence â†’ Block Decode è½¬æ¢å®Œæˆ**

âœ… **BlockInfer å¼•æ“å®Œæ•´é›†æˆ**:
- LLM() æ¥å£
- Scheduler block è°ƒåº¦
- Sequence block ç®¡ç†
- æƒé‡è‡ªåŠ¨åŠ è½½

âœ… **æƒé‡æ˜ å°„æœºåˆ¶å»ºç«‹**:
- è‡ªåŠ¨æ£€æµ‹ LLaDA æ¨¡å‹
- QKV èåˆ
- Gate-Up èåˆ
- 194 æƒé‡æˆåŠŸåŠ è½½

âœ… **Pipeline éªŒè¯é€šè¿‡**:
- Prefill æ­£ç¡®
- Block-wise denoise æ­£ç¡®
- Block åˆ‡æ¢æ­£ç¡®
- ååé‡ç¨³å®š

---

## ğŸ“ æŠ€æœ¯æ€»ç»“

### å®ç°çš„æ ¸å¿ƒ

**Block Decode = åˆ†å—è¿­ä»£å»å™ª**

ä¸æ˜¯ä¸€æ¬¡æ€§å»å™ªæ•´ä¸ªåºåˆ—ï¼Œè€Œæ˜¯ï¼š
1. å»å™ª block 1
2. æäº¤ block 1
3. å»å™ª block 2
4. æäº¤ block 2
...

**ä¼˜åŠ¿**:
- æ›´å¥½çš„å†…å­˜æ•ˆç‡
- æ”¯æŒæµå¼ç”Ÿæˆ
- æ˜“äºæ‰¹å¤„ç†
- å¯å¹¶è¡Œå¤„ç†å¤šblock

**å®ç°åœ¨**:
- `Scheduler.postprocess()`: Block å»å™ªé€»è¾‘
- `Sequence`: Block çŠ¶æ€è·Ÿè¸ª
- `ModelRunner`: å‡†å¤‡ denoise è¾“å…¥

---

**çŠ¶æ€**: âœ… Pipeline å®Œæ•´  
**æƒé‡**: âœ… 194/291 åŠ è½½  
**è¾“å‡º**: âš ï¸ éœ€è¦å®Œæ•´æƒé‡  
**å¯ç”¨**: âœ… ç»“æ„æ­£ç¡®ï¼Œå¯ç»§ç»­ä¼˜åŒ–

